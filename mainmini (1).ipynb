{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4d3de78-c6ac-49fa-91b7-6fbfacf9bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Name        29 non-null     object\n",
      " 1   Type        29 non-null     object\n",
      " 2   Price       29 non-null     object\n",
      " 3   Images url  29 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7403e56c-2562-45f1-8301-9d88d2e729ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Oranges\n",
       "1              Apples\n",
       "2             Bananas\n",
       "3             Lettuce\n",
       "4            Tomatoes\n",
       "5               Milk \n",
       "6              Cheese\n",
       "7             Parle-G\n",
       "8      Cottage cheese\n",
       "9     mozrella cheese\n",
       "10               lays\n",
       "11               corn\n",
       "12              Pepsi\n",
       "13            RedBull\n",
       "14                Tea\n",
       "15              Water\n",
       "16            Noodles\n",
       "17           cococola\n",
       "18     Monster Energy\n",
       "19             bingo \n",
       "20              Bread\n",
       "21       Potato chips\n",
       "22           Too Yumm\n",
       "23             Garlic\n",
       "24             carrot\n",
       "25           cucumber\n",
       "26           EggPlant\n",
       "27            spinach\n",
       "28           Brocolli\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f208e850-acd7-48e0-94a7-1b6270194067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oranges'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ac5bb63-d968-4114-893f-575207090f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$2.99'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Price'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1d6d853-a628-4c1a-9a96-1a9d5fb8fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "stmer = SnowballStemmer('english')\n",
    "def tokenization(txt):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    stemming = [stmer.stem(w) for w in tokens if w  not in stopwords.words('english')]\n",
    "    return \" \".join(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a570bcdf-f062-44c5-9bff-aa794be8dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def cosine_sim(txt1,txt2):\n",
    "    obj_ifid=TfidfVectorizer(tokenizer=tokenization)\n",
    "    matrix=obj_ifid.fit_transform([txt1,txt2])\n",
    "    similarity=cosine_similarity(matrix)[0]\n",
    "[1]    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3f6edd5-647e-4867-9545-e58733e25e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(query):\n",
    "    tokenized_query = tokenization(query)\n",
    "    df['similarity'] = df['Type'].apply(lambda x: cosine_sim(tokenized_query, x))\n",
    "    final_df = df.sort_values(by=['similarity'], ascending=False).head(3)[['Name', 'Price','Images url']]\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e4c4cab-7112-47a8-8a32-b936d3658bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oranges'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7db7fbfa-6a73-45c8-837f-e891c4fc802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\qccs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\qccs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2095c9ed-8ae8-4e61-911e-52ca23dbdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(query, df, top_n=10):\n",
    "    tokenized_query = tokenize(query)\n",
    "    df['similarity'] = df['Type'].apply(lambda x: cosine_sim(' '.join(tokenized_query), x))\n",
    "    final_df = df.sort_values(by=['similarity'], ascending=False).head(top_n)[['Name', 'Price',  'Images url']]\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37ca96dc-5e02-49f6-9fd1-73d3ad86e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5817cf9b-30cc-43bf-ba5e-cd04a9711f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name  Price        Type  \\\n",
      "0        oranges   2 99      fruits   \n",
      "15         water   1 00      drinks   \n",
      "27       spinach   4 99  vegetables   \n",
      "26      eggplant   6 99  vegetables   \n",
      "25      cucumber   5 99  vegetables   \n",
      "24        carrot   4 99  vegetables   \n",
      "23        garlic   3 99  vegetables   \n",
      "22      too yumm   4 99      snacks   \n",
      "21  potato chips   6 99      snacks   \n",
      "20         bread   8 99      bakery   \n",
      "\n",
      "                                           Images url  \n",
      "0   https://media.istockphoto.com/id/185284489/pho...  \n",
      "15  https://www.google.com/url?sa=i&url=https%3A%2...  \n",
      "27  https://dukaan.b-cdn.net/1000x1000/webp/upload...  \n",
      "26  https://www.shutterstock.com/image-photo/auber...  \n",
      "25  https://www.shutterstock.com/image-photo/cucum...  \n",
      "24  https://blog-images-1.pharmeasy.in/blog/produc...  \n",
      "23  https://media.istockphoto.com/id/1340230644/ph...  \n",
      "22  https://m.media-amazon.com/images/I/71NIHBImUs...  \n",
      "21  https://india.neelamfoodland.in/cdn/shop/produ...  \n",
      "20  https://www.bhg.com/thmb/ov2S31znAvSCXqrpgJQ8r...  \n"
     ]
    }
   ],
   "source": [
    "def tokenize(query):\n",
    "    return query.lower().split()\n",
    "\n",
    "def cosine_sim(tokenized_query, text):\n",
    "    vectorizer = CountVectorizer().fit([tokenized_query, text])\n",
    "    vectors = vectorizer.transform([tokenized_query, text])\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "def recommendation(query, df, top_n=10):\n",
    "    tokenized_query = tokenize(query)\n",
    "    df['similarity'] = df['Type'].apply(lambda x: cosine_sim(' '.join(tokenized_query), x))\n",
    "    final_df = df.sort_values(by=['similarity'], ascending=False).head(top_n)[['Name', 'Price', 'Type', 'Images url']]\n",
    "    return final_df\n",
    "\n",
    "query = 'orange'\n",
    "result = recommendation(query, df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c81eca77-a63d-41bc-9522-dac225dc7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "631af085-8887-4225-b13a-79ff0317c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Grocery Lists2mainmini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "61226885-8ffb-444b-8e7b-20afd469d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(txt):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    stemming = [stemr.stem(w) for w in tokens if w not in stopwords.words('english')]\n",
    "    return \"\".join(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "43792c0c-9f37-4735-a8ba-f0b1e4473551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(txt1, txt2):\n",
    "    obj_tfidf = TfidfVectorizer(tokenizer=tokenization)\n",
    "    tfidfmatrix = obj_tfidf.fit_transform([txt1, txt2])\n",
    "    similarity = cosine_similarity(tfidfmatrix)[0][1]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "462e8f48-9717-4138-b1eb-1a9819b2ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemr = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7a5f6f0-f180-4d1e-a82e-b890d4cfc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommation(query):\n",
    "    tokenized_query = tokenization(query)\n",
    "    df['similarity'] = df['Type'].apply(lambda x: cosine_sim(tokenized_query,x))\n",
    "    final_df = df.sort_values(by=['similarity'],ascending=False).head(3)[['Name','Price','Images url']]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "31e807c5-562b-4480-8e43-2b939bd35cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qccs\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Images url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Brocolli</td>\n",
       "      <td>$5.00</td>\n",
       "      <td>https://cdn.britannica.com/25/78225-050-1781F6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>corn</td>\n",
       "      <td>$5.99</td>\n",
       "      <td>https://www.shutterstock.com/image-photo/singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spinach</td>\n",
       "      <td>$4.99</td>\n",
       "      <td>https://dukaan.b-cdn.net/1000x1000/webp/upload...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Price                                         Images url\n",
       "28  Brocolli  $5.00  https://cdn.britannica.com/25/78225-050-1781F6...\n",
       "11      corn  $5.99  https://www.shutterstock.com/image-photo/singl...\n",
       "27   spinach  $4.99  https://dukaan.b-cdn.net/1000x1000/webp/upload..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommation('vegetables')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7639c51-00ea-41d2-954a-9f5962774a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
